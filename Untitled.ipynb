{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426584bf-3aa9-4a01-92ee-3130cf8496ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Essential Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Processing and Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Hugging Face and NLP Libraries\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395c56b9-f26d-4223-b66c-394dde2a2da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>footfall</th>\n",
       "      <th>tempMode</th>\n",
       "      <th>AQ</th>\n",
       "      <th>USS</th>\n",
       "      <th>CS</th>\n",
       "      <th>VOC</th>\n",
       "      <th>RP</th>\n",
       "      <th>IP</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   footfall  tempMode  AQ  USS  CS  VOC  RP  IP  Temperature  fail\n",
       "0         0         7   7    1   6    6  36   3            1     1\n",
       "1       190         1   3    3   5    1  20   4            1     0\n",
       "2        31         7   2    2   6    1  24   6            1     0\n",
       "3        83         4   3    4   5    1  28   6            1     0\n",
       "4       640         7   5    6   4    0  68   6            1     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Data Loading\n",
    "# Load Kaggle Machine Failure Dataset\n",
    "sensor_data = pd.read_csv(r\"C:\\Users\\ishir\\Enhancing-Predictive-Maintenance-with-Multi-Source-Data-Integration\\sensor_dataset\\data.csv\")\n",
    "\n",
    "# Load FabNER dataset from Hugging Face\n",
    "fabner_dataset = load_dataset('DFKI-SLT/fabner')\n",
    "\n",
    "sensor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc222a9-26b4-4890-a72e-bd5737040696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 944 entries, 0 to 943\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   footfall     944 non-null    int64\n",
      " 1   tempMode     944 non-null    int64\n",
      " 2   AQ           944 non-null    int64\n",
      " 3   USS          944 non-null    int64\n",
      " 4   CS           944 non-null    int64\n",
      " 5   VOC          944 non-null    int64\n",
      " 6   RP           944 non-null    int64\n",
      " 7   IP           944 non-null    int64\n",
      " 8   Temperature  944 non-null    int64\n",
      " 9   fail         944 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 73.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Exploration and Preprocessing\n",
    "# Sensor Data Cleaning\n",
    "print(\"Sensor Data Info:\")\n",
    "print(sensor_data.info())\n",
    "\n",
    "# Handle missing values in sensor data\n",
    "sensor_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d8da782-c030-4ffc-b7d8-a3e1601e13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FabNER Dataset Feature Extraction\n",
    "# Prepare tokenizer and model for feature extraction\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_bert_features(texts):\n",
    "    \"\"\"\n",
    "    Extract BERT embeddings for text features using PyTorch\n",
    "    \"\"\"\n",
    "    # Prepare features list\n",
    "    bert_features = []\n",
    "    \n",
    "    for text in texts:\n",
    "        # Tokenize and encode text\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        \n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        \n",
    "        # Use [CLS] token embedding (first token)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        bert_features.append(embeddings[0])\n",
    "    \n",
    "    return np.array(bert_features)\n",
    "\n",
    "# Extract text features from FabNER dataset\n",
    "fabner_texts = []\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for item in fabner_dataset[split]:\n",
    "        # Combine all entity texts and original text\n",
    "        combined_text = ' '.join([\n",
    "            str(item.get('text', '')),\n",
    "            ' '.join([str(entity) for entity in item.get('entities', [])])\n",
    "        ])\n",
    "        fabner_texts.append(combined_text)\n",
    "\n",
    "# Extract BERT features\n",
    "fabner_features = extract_bert_features(fabner_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c13ae1b0-4b2d-42e7-839c-1cf886c439b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Preprocessing\n",
    "# Numerical Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_features = sensor_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "sensor_data[numerical_features] = scaler.fit_transform(sensor_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f46fea-b582-40de-9751-6e3c4a5e398d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'failure_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'failure_label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X_sensor, X_fabner])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare target variable\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m y \u001b[38;5;241m=\u001b[39m sensor_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailure_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'failure_label'"
     ]
    }
   ],
   "source": [
    "# 5. Multi-Modal Data Preparation\n",
    "# Combine sensor data with FabNER features\n",
    "X_sensor = sensor_data[numerical_features]\n",
    "X_fabner = fabner_features[:len(X_sensor)]  # Ensure same length\n",
    "\n",
    "# Combine sensor and FabNER features\n",
    "X_combined = np.hstack([X_sensor, X_fabner])\n",
    "\n",
    "# Prepare target variable\n",
    "y = sensor_data['failure_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fdb3f-f385-4876-873b-f8c55d6d3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3f549-b329-42c0-9be0-3bbfbce6b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Multiple Model Approaches\n",
    "\n",
    "# Approach 1: Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train Random Forest\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Approach 2: Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "gb_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, gb_pred))\n",
    "\n",
    "# Approach 3: Support Vector Machine\n",
    "svm_classifier = SVC(\n",
    "    kernel='rbf', \n",
    "    probability=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train SVM\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510eb3b-da7b-40b5-9350-d5a282f78a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Custom PyTorch Neural Network (Alternative to TensorFlow)\n",
    "class MultiModalNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MultiModalNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# PyTorch Model Training\n",
    "def train_pytorch_model(X_train, y_train, X_test, y_test):\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MultiModalNetwork(input_size=X_train.shape[1])\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_predictions = (test_outputs > 0.5).float()\n",
    "        accuracy = (test_predictions == y_test_tensor).float().mean()\n",
    "        print(f'\\nPyTorch Model Test Accuracy: {accuracy.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train PyTorch Model\n",
    "pytorch_model = train_pytorch_model(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefeb654-c9bb-4e68-afbb-a820f5adc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Visualization of Model Comparisons\n",
    "# Create performance comparison plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = ['Random Forest', 'Gradient Boosting', 'SVM']\n",
    "accuracies = [\n",
    "    rf_classifier.score(X_test, y_test),\n",
    "    gb_classifier.score(X_test, y_test),\n",
    "    svm_classifier.score(X_test, y_test)\n",
    "]\n",
    "\n",
    "plt.bar(models, accuracies)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278276e-2362-4f8d-9275-13ce9d86616d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
